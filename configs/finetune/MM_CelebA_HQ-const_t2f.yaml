data:
  dataset: MM-CelebA-HQ
  category: lmdb
  resolution: 32
  num_channels: 4
  root: data/MM_CelebA_HQ/MM_CelebA_HQ_lmdb/z
  feat_path: data/MM_CelebA_HQ/MM_CelebA_HQ_lmdb/clip_txt
  feat_dim: 512

model:
  precond: edm
  model_type: DiT-XL/2
  in_size: 32
  in_channels: 4 
  num_classes: 512
  use_decoder: True
  ext_feature_dim: 0
  pad_cls_token: False
  mask_ratio: 0.0
  mask_ratio_fn: constant
  mask_ratio_min: 0
  mae_loss_coef: 0.1
  self_cond: False
  class_dropout_prob: 0 # 1 for unconditional, 0 for conditional

train:
  tf32: True
  amp: False
  batchsize: 64   # batchsize per GPU
  grad_accum: 1
  epochs: 5_000
  lr: 0.00005
  lr_rampup_kimg: 0
  xflip: False
  max_num_steps: 1_000_000

eval: # FID evaluation
  batchsize: 50
  ref_path: data/MM_CelebA_HQ/fid_refs/test_fid_ref.npz
  fid_sample_size: 256 # testset size

log:
  log_every: 50
  ckpt_every: 5_000
  tag: finetune-const
  use_tensorboard: True

