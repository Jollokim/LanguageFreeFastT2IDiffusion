data:
  dataset: MM-CelebA-HQ
  category: lmdb
  resolution: 32
  num_channels: 4
  root: data/MM_CelebA_HQ/MM_CelebA_HQ_lmdb/z
  feat_path: data/MM_CelebA_HQ/MM_CelebA_HQ_lmdb/clip_txt
  feat_dim: 512
  norm_feature: True

model:
  precond: edm
  model_type: DiT-XL/2
  in_size: 32
  in_channels: 4 
  num_classes: 512
  use_decoder: True
  ext_feature_dim: 0
  pad_cls_token: False
  mask_ratio: 0.5
  mask_ratio_fn: constant
  mask_ratio_min: 0
  mae_loss_coef: 0.1
  self_cond: False
  class_dropout_prob: 0.1 # 1 for unconditional, 0 for conditional
  perturbation: False # learnable perturbation True or False

train:
  tf32: False
  amp: True
  batchsize: 128   # batchsize per GPU
  grad_accum: 1
  epochs: 10_000
  lr: 0.00001
  lr_rampup_kimg: 0
  xflip: False
  max_num_steps: 300_000
  perturbation: 0 # fixed perturbation [0, 1]

eval: # FID evaluation
  batchsize: 50
  ref_path: data/MM_CelebA_HQ/fid_refs/test_fid_ref.npz
  fid_sample_size: 1024 # testset size
  feat_path: data/MM_CelebA_HQ/MM_CelebA_HQ_lmdb/clip_txt

log:
  log_every: 50
  ckpt_every: 1_000 #12_500
  tag: from_ffhq_finetuneceleb_noperb
  use_tensorboard: True
