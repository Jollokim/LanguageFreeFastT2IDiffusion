data:
  dataset: MM-CelebA-HQ
  category: lmdb
  resolution: 32
  num_channels: 4
  root: data/MM_CelebA_HQ/MM_CelebA_HQ_lmdb/z
  feat_path: data/MM_CelebA_HQ/MM_CelebA_HQ_lmdb/clip_txt
  feat_dim: 512

model:
  precond: edm
  model_type: DiT-XL/2
  in_size: 32
  in_channels: 4 
  num_classes: 512
  use_decoder: True
  ext_feature_dim: 0
  pad_cls_token: False
  mask_ratio: 0.5
  mask_ratio_fn: constant
  mask_ratio_min: 0
  mae_loss_coef: 0.1
  self_cond: False
  class_dropout_prob: 0.1 # 1 for unconditional, 0 for conditional

train:
  tf32: False
  amp: True
  batchsize: 128   # batchsize per GPU
  grad_accum: 1
  epochs: 10_000
  lr: 0.0001
  lr_rampup_kimg: 0
  xflip: False
  max_num_steps: 2_000_000

eval: # FID evaluation
  batchsize: 50
  ref_path: data/MM_CelebA_HQ/fid_refs/all_fid_ref.npz
  fid_sample_size: 30_000 # testset size

log:
  log_every: 50
  ckpt_every: 5_000 #12_500
  tag: pretrain_clsdrop0.1_transfer-ffhq
  use_tensorboard: True
